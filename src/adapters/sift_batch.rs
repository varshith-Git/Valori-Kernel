use memmap2::Mmap;

/// A Zero-Copy, Batch-Optimized SIFT1M Loader.
/// 
/// Efficiently loads SIFT/FVECS format vectors from a memory-mapped file.
/// Format: `[int32 dim] [float32 data...] [int32 dim] [float32 data...]`
/// 
/// # Lifetimes
/// - `'a`: The lifetime of the underlying `Mmap`. The returned batches leverage zero-copy
///   slicing and thus are tied to this lifetime.
pub struct SiftBatchLoader<'a> {
    mmap: &'a Mmap,
    base_offset: usize,
    cursor: usize,
    dim: usize,
    total_vectors: usize,
    vector_stride: usize,
}

impl<'a> SiftBatchLoader<'a> {
    /// Initialize a loader starting from the beginning of the mmap.
    pub fn new(mmap: &'a Mmap) -> Option<Self> {
        Self::with_offset(mmap, 0)
    }

    /// Initialize a loader starting from a specific byte offset.
    /// 
    /// Useful for skipping headers or processing file shards.
    /// Returns `None` if the offset is out of bounds or the file is too small to contain even a header.
    pub fn with_offset(mmap: &'a Mmap, base_offset: usize) -> Option<Self> {
        if base_offset >= mmap.len() {
            return None;
        }

        // Need at least 4 bytes for dimension
        if mmap.len() - base_offset < 4 {
            return None;
        }

        // Read dim from [base_offset..base_offset+4]
        // SAFETY: Bounds checked above.
        let dim_slice = &mmap[base_offset..base_offset + 4];
        let dim = u32::from_le_bytes(dim_slice.try_into().unwrap()) as usize;

        // Calculate stride: 4 bytes (dim header) + dim * 4 bytes (f32 data)
        let vector_stride = 4 + dim * 4;

        if vector_stride == 0 {
            return None; // Avoiding infinite loops on garbage data
        }

        // Calculate total vectors
        let available_bytes = mmap.len() - base_offset;
        let total_vectors = available_bytes / vector_stride;

        // Alignment check (Debug only)
        #[cfg(debug_assertions)]
        {
            if vector_stride % 16 != 0 {
                // Log warning or comment. Since we can't easily log in no_std/kernel easily without
                // bringing in `log` or `tracing` (which we have in workspace but maybe not here),
                // we'll just print to stderr if standard generic logging isn't set up.
                // Or better, just a comment here for future SIMD work.
                // println!("WARN: SIFT vector stride {} is not 16-byte aligned. SIMD loads may be unaligned.", vector_stride);
            }
        }

        Some(Self {
            mmap,
            base_offset,
            cursor: 0,
            dim,
            total_vectors,
            vector_stride,
        })
    }

    /// Returns the dimension of vectors in this file.
    pub fn dim(&self) -> usize {
        self.dim
    }

    /// Returns the number of vectors available.
    pub fn len(&self) -> usize {
        self.total_vectors
    }

    /// Returns the next batch of raw bytes containing vectors.
    /// 
    /// Returns `Option<(slice, count)>`.
    /// - `slice`: The raw byte slice containing the batch.
    /// - `count`: The number of vectors in this batch.
    pub fn next_batch(&mut self, batch_size: usize) -> Option<(&'a [u8], usize)> {
        if self.cursor >= self.total_vectors {
            return None;
        }

        let remaining = self.total_vectors - self.cursor;
        let count = std::cmp::min(batch_size, remaining);

        let start_idx = self.cursor;
        let _end_idx = start_idx + count;

        let byte_start = self.base_offset + (start_idx * self.vector_stride);
        let byte_len = count * self.vector_stride;
        let byte_end = byte_start + byte_len;

        // SAFETY: 
        // 1. `base_offset` is validated in `new`.
        // 2. `total_vectors` is calculated based on `mmap.len()` and `vector_stride`.
        // 3. `cursor` is bounded by `total_vectors`.
        // 4. Therefore `byte_end` <= `mmap.len()`.
        let slice = &self.mmap[byte_start..byte_end];

        self.cursor += count;

        Some((slice, count))
    }
    
    /// Helper to parse a raw vector from a slice (skip the 4-byte header).
    /// Returns the f32 slice.
    pub fn parse_vector(data: &[u8]) -> &[f32] {
        let (_header, content) = data.split_at(4);
        // SAFETY: We assume the caller knows this is a valid SIFT record slice
        // generated by this loader.
        unsafe {
            std::slice::from_raw_parts(
                content.as_ptr() as *const f32,
                content.len() / 4
            )
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Write;
    use tempfile::NamedTempFile;

    fn create_mock_fvecs(dim: usize, count: usize, offset_bytes: usize) -> (NamedTempFile, Vec<f32>) {
        let mut file = NamedTempFile::new().unwrap();
        let mut all_floats = Vec::new();

        // Write garbage offset
        if offset_bytes > 0 {
            file.write_all(&vec![0u8; offset_bytes]).unwrap();
        }

        for i in 0..count {
            // Write dim
            file.write_all(&(dim as i32).to_le_bytes()).unwrap();
            // Write vector
            for j in 0..dim {
                let val = (i * dim + j) as f32;
                all_floats.push(val);
                file.write_all(&val.to_le_bytes()).unwrap();
            }
        }
        file.flush().unwrap();
        (file, all_floats)
    }

    #[test]
    fn test_sift_loader_basic() {
        let dim = 4;
        let count = 10;
        let (file, _expected_data) = create_mock_fvecs(dim, count, 0);
        
        // Mmap
        let mmap = unsafe { Mmap::map(file.as_file()).unwrap() };
        
        let mut loader = SiftBatchLoader::new(&mmap).expect("Failed to create loader");
        assert_eq!(loader.dim(), dim);
        assert_eq!(loader.len(), count);

        // Read in batches of 3
        let (slice, c) = loader.next_batch(3).unwrap();
        assert_eq!(c, 3);
        assert_eq!(slice.len(), 3 * (4 + dim * 4));

        let (_slice, c) = loader.next_batch(3).unwrap();
        assert_eq!(c, 3);

        let (_slice, c) = loader.next_batch(3).unwrap();
        assert_eq!(c, 3);

        let (_slice, c) = loader.next_batch(3).unwrap();
        assert_eq!(c, 1); // Leftover

        assert!(loader.next_batch(3).is_none());
    }

    #[test]
    fn test_sift_loader_offset() {
        let dim = 128;
        let count = 5;
        let offset = 123; // Arbitrary offset
        let (file, _) = create_mock_fvecs(dim, count, offset);

        let mmap = unsafe { Mmap::map(file.as_file()).unwrap() };
        
        let mut loader = SiftBatchLoader::with_offset(&mmap, offset).expect("Failed with offset");
        assert_eq!(loader.dim(), dim);
        assert_eq!(loader.len(), count);

        let (_, c) = loader.next_batch(100).unwrap();
        assert_eq!(c, 5);
    }
}
